{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrx52s2axGM-"
      },
      "source": [
        "#**Check for GPU Availability**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOmj0QhaEIfv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"Checking GPU availability...\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"✅ GPU is available: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"❌ No GPU detected! Please change runtime to GPU:\")\n",
        "    print(\"Runtime > Change runtime type > Hardware accelerator > GPU\")\n",
        "    raise RuntimeError(\"GPU not available\")\n",
        "\n",
        "# Install system dependencies\n",
        "!apt -q install -y libgl1-mesa-glx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtZpHJlF3O02"
      },
      "source": [
        "#**Clone ComfyUI & Install Requirements**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPPiwjHGEMd-"
      },
      "outputs": [],
      "source": [
        "import os, sys, subprocess\n",
        "\n",
        "# ── 1) Reset to /workspace ──────────────────────────────────\n",
        "try:\n",
        "    os.chdir('/workspace')\n",
        "except Exception:\n",
        "    pass  # in case /workspace doesn't exist (it always does on Runpod)\n",
        "\n",
        "# ── 2) Install cloudflared ─────────────────────────────────\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'cloudflared'], check=True)\n",
        "\n",
        "# ── 3) Define paths ───────────────────────────────────────\n",
        "COMFY = '/workspace/ComfyUI'\n",
        "\n",
        "# ── 4) Check & abort if already cloned ───────────────────\n",
        "if os.path.isdir(COMFY):\n",
        "    print(\"❌ ERROR: '/workspace/ComfyUI' already exists.\")\n",
        "    print(\"👉 Remove it first with:\\n   !rm -rf /workspace/ComfyUI\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# ── 5) Clone & install ────────────────────────────────────\n",
        "subprocess.run(['git', 'clone', 'https://github.com/comfyanonymous/ComfyUI', COMFY], check=True)\n",
        "os.chdir(COMFY)\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'], check=True)\n",
        "\n",
        "print(\"✔ ComfyUI cloned and requirements installed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqXmdGO3hX-B"
      },
      "source": [
        "# Install ComfyUI Manager & Custom Nodes\n",
        "Note: ComfyUI-Manager is essential for managing ComfyUI - Do not remove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgBYRT_dhTri"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# GitHub URLs - Add your custom nodes here\n",
        "github_urls = [\n",
        "    \"https://github.com/ltdrdata/ComfyUI-Manager\",  # Essential - DO NOT REMOVE\n",
        "    # Add additional custom nodes below:\n",
        "\n",
        "]\n",
        "\n",
        "def clone_node(url):\n",
        "    try:\n",
        "        repo_name = url.split('/')[-1].replace('.git', '')\n",
        "        dest = f\"/workspace/ComfyUI/custom_nodes/{repo_name}\"\n",
        "\n",
        "        if os.path.exists(dest):\n",
        "            print(f\"⏭️  {repo_name} already exists\")\n",
        "            return\n",
        "\n",
        "        subprocess.run(['git', 'clone', url, dest], check=True)\n",
        "        print(f\"✅ Installed {repo_name}\")\n",
        "\n",
        "        # Install requirements if present\n",
        "        req_file = f\"{dest}/requirements.txt\"\n",
        "        if os.path.exists(req_file):\n",
        "            subprocess.run(['pip', 'install', '-r', req_file], check=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed: {url.split('/')[-1]} - {e}\")\n",
        "\n",
        "# Create directory and install nodes\n",
        "os.makedirs(\"/workspace/ComfyUI/custom_nodes\", exist_ok=True)\n",
        "\n",
        "print(\"📦 Installing custom nodes...\")\n",
        "for url in github_urls:\n",
        "    if url.strip():\n",
        "        clone_node(url.strip())\n",
        "\n",
        "print(\"✨ Installation complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMQjyys1xfG-"
      },
      "source": [
        "#**Download Models By ID (optional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhNaaVMlEKTT"
      },
      "outputs": [],
      "source": [
        "import os, re, sys, requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "API_KEY = \"API_KEY\"  # ← set your CivitAI key\n",
        "BASE     = \"/workspace/ComfyUI/models\"\n",
        "\n",
        "# ─── Paste your URLs here ────────────────────────────────────────────────\n",
        "ckpt_links = [\n",
        "    \"https://civitai.com/models/372465?modelVersionId=914390\",\n",
        "    \"https://civitai.com/models/439889?modelVersionId=1199750\",\n",
        "    \"https://civitai.com/models/795765/illustrious-xl\"\n",
        "\n",
        "]\n",
        "\n",
        "lora_links = [\n",
        "    \"https://civitai.com/models/696418?modelVersionId=779327\",\n",
        "    \"https://civitai.com/models/1327644?modelVersionId=1498957\",\n",
        "    \"https://civitai.com/models/1333749/add-detail-slider\",\n",
        "    \"https://civitai.com/models/669571/pony-add-more-details\",\n",
        "    \"https://civitai.com/models/454172?modelVersionId=505635\",\n",
        "    \"https://civitai.com/models/300005?modelVersionId=436219\",\n",
        "    \"https://civitai.com/models/73756?modelVersionId=703107\"\n",
        "\n",
        "]\n",
        "\n",
        "vae_links = [\n",
        "    \"https://civitai.com/models/199948?modelVersionId=224985\"\n",
        "]\n",
        "\n",
        "embedding_links = [\n",
        "    \"https://civitai.com/models/118418?modelVersionId=134583\",\n",
        "    \"https://civitai.com/models/583583?modelVersionId=651084\"\n",
        "]\n",
        "\n",
        "controlnet_links = [\n",
        "    # add ControlNet URLs here…\n",
        "]\n",
        "# ──────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "if not API_KEY:\n",
        "    print(\"❌ Set your API_KEY\"); sys.exit(1)\n",
        "\n",
        "# prep folders\n",
        "for folder in (\"checkpoints\",\"loras\",\"vae\",\"embeddings\",\"controlnet\"):\n",
        "    os.makedirs(os.path.join(BASE, folder), exist_ok=True)\n",
        "\n",
        "def parse_mid_and_override(url):\n",
        "    m = re.search(r\"models/(\\d+)\", url)\n",
        "    if not m:\n",
        "        raise ValueError(f\"Bad URL: {url}\")\n",
        "    mid = m.group(1)\n",
        "    over = re.search(r\"modelVersionId=(\\d+)\", url)\n",
        "    return mid, (over.group(1) if over else None)\n",
        "\n",
        "def get_vid(mid):\n",
        "    h = {\"Authorization\":f\"Bearer {API_KEY}\"}\n",
        "    r = requests.get(f\"https://civitai.com/api/v1/models/{mid}\", headers=h, timeout=10)\n",
        "    r.raise_for_status()\n",
        "    return r.json()[\"modelVersions\"][0][\"id\"]\n",
        "\n",
        "def fetch_dl_info(vid):\n",
        "    h = {\"Authorization\":f\"Bearer {API_KEY}\"}\n",
        "    r = requests.get(f\"https://civitai.com/api/v1/model-versions/{vid}\", headers=h, timeout=10)\n",
        "    r.raise_for_status()\n",
        "    j = r.json()\n",
        "    return j[\"downloadUrl\"], j[\"files\"][0][\"name\"]\n",
        "\n",
        "def download(url, dest_folder):\n",
        "    try:\n",
        "        mid, override = parse_mid_and_override(url)\n",
        "        vid = override or get_vid(mid)\n",
        "        dl_url, fname = fetch_dl_info(vid)\n",
        "    except Exception as e:\n",
        "        print(f\"✖ Error resolving {url}: {e}\")\n",
        "        return\n",
        "\n",
        "    path = os.path.join(BASE, dest_folder, fname)\n",
        "    r = requests.get(dl_url, headers={\"Authorization\":f\"Bearer {API_KEY}\"}, stream=True)\n",
        "    if r.status_code != 200:\n",
        "        print(f\"✖ Download failed {fname}: HTTP {r.status_code}\")\n",
        "        return\n",
        "\n",
        "    total = int(r.headers.get(\"content-length\", 0))\n",
        "    bar = tqdm(total=total, unit=\"iB\", unit_scale=True, desc=fname)\n",
        "    with open(path, \"wb\") as f:\n",
        "        for chunk in r.iter_content(8192):\n",
        "            f.write(chunk); bar.update(len(chunk))\n",
        "    bar.close()\n",
        "    print(f\"✔ Saved → {path}\")\n",
        "\n",
        "# ─── Kick off downloads ───────────────────────────────────────────────────\n",
        "\n",
        "print(\"Downloading checkpoints…\")\n",
        "for u in ckpt_links:      download(u, \"checkpoints\")\n",
        "\n",
        "print(\"Downloading LoRAs…\")\n",
        "for u in lora_links:      download(u, \"loras\")\n",
        "\n",
        "print(\"Downloading VAEs…\")\n",
        "for u in vae_links:       download(u, \"vae\")\n",
        "\n",
        "print(\"Downloading embeddings…\")\n",
        "for u in embedding_links: download(u, \"embeddings\")\n",
        "\n",
        "print(\"Downloading ControlNets…\")\n",
        "for u in controlnet_links: download(u, \"controlnet\")\n",
        "\n",
        "print(\"\\n✨ All done.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Download Model At Custom Location Via Civitai (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Configuration\n",
        "api_key = \"API_KEY\"  # ← set your CivitAI key\n",
        "model_id = \"116225\"   # Replace with your Model ID\n",
        "download_location = \"/workspace/ComfyUI/models/upscale_models/\"  # Replace it with your Location\n",
        "\n",
        "# Create download directory if it doesn't exist\n",
        "os.makedirs(download_location, exist_ok=True)\n",
        "\n",
        "# Get model info\n",
        "url = f\"https://civitai.com/api/v1/models/{model_id}\"\n",
        "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
        "\n",
        "try:\n",
        "    response = requests.get(url, headers=headers)\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        model_data = response.json()\n",
        "        download_url = model_data[\"modelVersions\"][0][\"files\"][0][\"downloadUrl\"]\n",
        "        filename = model_data[\"modelVersions\"][0][\"files\"][0][\"name\"]\n",
        "        \n",
        "        print(f\"Downloading: {filename}\")\n",
        "        print(f\"From: {download_url}\")\n",
        "        \n",
        "        # Download the file\n",
        "        download_response = requests.get(download_url, headers=headers, stream=True)\n",
        "        \n",
        "        if download_response.status_code == 200:\n",
        "            file_path = os.path.join(download_location, filename)\n",
        "            \n",
        "            with open(file_path, 'wb') as f:\n",
        "                for chunk in download_response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "            \n",
        "            print(f\"Downloaded successfully to: {file_path}\")\n",
        "        else:\n",
        "            print(f\"Download failed: {download_response.status_code}\")\n",
        "            \n",
        "    else:\n",
        "        print(f\"Error getting model info: {response.status_code} - {response.text}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo4vgBbExyP8"
      },
      "source": [
        "# **Run ComfyUI and Access via Local Tunnel**\n",
        "\n",
        "**Note:** ComfyUI lacks Gradio's `--share` option, so we use LocalTunnel to expose localhost:8188 to your browser.\n",
        "\n",
        "## Why LocalTunnel via Node.js?\n",
        "\n",
        "1. **Cloudflared:** Too slow and unreliable\n",
        "2. **Ngrok & Pinggy:** Limited free usage, may require accounts  \n",
        "3. **LocalTunnel:** Fast, reliable, no account needed, full control\n",
        "\n",
        "**Benefits:** Zero configuration, custom subdomains, consistent performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgmtwUZhg5Gv"
      },
      "outputs": [],
      "source": [
        "# Kill processes on port 8188 if it says port 8188 is already running or take too much time loading\n",
        "# logs at /workspace/ComfyUI/comfyui.log\n",
        "# logs at /workspace/ComfyUI/tunnel.log\n",
        "!lsof -ti:8188 | xargs -r kill -9\n",
        "!pkill -f \"main.py\"\n",
        "print(\"✅ Port 8188 cleaned up\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mB2FRvrb3wY3"
      },
      "outputs": [],
      "source": [
        "# Install Node.js silently in background\n",
        "!curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash - > /dev/null 2>&1\n",
        "!apt-get install -y nodejs > /dev/null 2>&1\n",
        "!npm install -g localtunnel > /dev/null 2>&1\n",
        "\n",
        "# Start ComfyUI\n",
        "%cd /workspace/ComfyUI\n",
        "!nohup python main.py --listen 0.0.0.0 --port 8188 > comfyui.log 2>&1 &\n",
        "!sleep 10\n",
        "\n",
        "# Start tunnel \n",
        "!nohup lt --port 8188 > tunnel.log 2>&1 &\n",
        "!sleep 5\n",
        "\n",
        "# Show URL and password on same line\n",
        "!echo -n \"Your URL is: \"; cat tunnel.log | grep -o 'https://[^[:space:]]*'; echo -n \"Tunnel Password: \"; curl -s https://loca.lt/mytunnelpassword"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
