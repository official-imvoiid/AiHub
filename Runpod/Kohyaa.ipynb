{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HAf-sJC9Bn1"
   },
   "source": [
    "# Run Kohyaa in runpod\n",
    "# NoteBook Created by Voiid (https://github.com/official-imvoiid)\n",
    "📌 Recommended Setup:\n",
    "- GPU: A6000 Ada  \n",
    "- Storage: 70GB total  \n",
    "  - 50GB on persistent  \n",
    "  - 20GB on temporary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z29zzupW9Ymc"
   },
   "source": [
    "DIRECT MODEL DOWNLOAD VIA HUGGINGFACE IF YOU WANNA FINETUNE ON CUSTOM MODEL (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwlY4rXt899c"
   },
   "outputs": [],
   "source": [
    "# Install required library\n",
    "!pip install huggingface_hub\n",
    "\n",
    "from huggingface_hub import login, snapshot_download\n",
    "import os\n",
    "\n",
    "# Prompt for Hugging Face access token\n",
    "hf_token = input(\"Enter your Hugging Face access token: \")\n",
    "\n",
    "# Log in to Hugging Face\n",
    "login(hf_token)\n",
    "\n",
    "# Define model name and download directory\n",
    "model_name = input(\"Enter the Hugging Face model name (e.g., OnomaAIResearch/Illustrious-XL-v1.1): \")\n",
    "download_dir = \"/workspace/Model/HuggingFace/\"\n",
    "\n",
    "# Create download directory if it doesn't exist\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Download the model\n",
    "try:\n",
    "    snapshot_download(repo_id=model_name, local_dir=download_dir, allow_patterns=\"*\")\n",
    "    print(f\"Model {model_name} downloaded successfully to {download_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading model: {e}\")\n",
    "\n",
    "# List downloaded files\n",
    "if os.path.exists(download_dir):\n",
    "    print(\"\\nFiles in the download directory:\")\n",
    "    for root, dirs, files in os.walk(download_dir):\n",
    "        for file in files:\n",
    "            print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMgC1vIv-UZC"
   },
   "source": [
    "DIRECT MODEL DOWNLOAD VIA CIVITAI IF YOU WANNA FINETUNE ON CUSTOM MODEL (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1gVlGbX-K10"
   },
   "outputs": [],
   "source": [
    "# CivitAi Model Downloader Via API\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set your CivitAI API key here\n",
    "API_KEY = \"API_KEY\"  # ← set your CivitAI key\n",
    "\n",
    "# ─── Paste your URLs here ────────────────────────────────────────────────\n",
    "# Base directory paths\n",
    "CKPT_PATH = \"/workspace/Models/Civitai\"\n",
    "\n",
    "\n",
    "ckpt_links = [\n",
    "    \"https://civitai.com/models/257749/pony-diffusion-v6-xl\",\n",
    "    \"https://civitai.com/models/795765/illustrious-xl\",\n",
    "    \"https://civitai.com/models/101055/sd-xl\"\n",
    "]\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "# Check if API key is set\n",
    "if not API_KEY:\n",
    "    print(\"API key not set. Please set your CivitAI API key.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Create all required directories\n",
    "os.makedirs(CKPT_PATH, exist_ok=True)\n",
    "\n",
    "def parse_mid_and_override(url):\n",
    "    m = re.search(r\"models/(\\d+)\", url)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Bad URL: {url}\")\n",
    "    mid = m.group(1)\n",
    "    over = re.search(r\"modelVersionId=(\\d+)\", url)\n",
    "    return mid, (over.group(1) if over else None)\n",
    "\n",
    "def get_vid(mid):\n",
    "    h = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "    r = requests.get(\n",
    "        f\"https://civitai.com/api/v1/models/{mid}\", headers=h, timeout=10\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"modelVersions\"][0][\"id\"]\n",
    "\n",
    "def fetch_dl_info(vid):\n",
    "    h = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "    r = requests.get(\n",
    "        f\"https://civitai.com/api/v1/model-versions/{vid}\", headers=h, timeout=10\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "    j = r.json()\n",
    "    return j[\"downloadUrl\"], j[\"files\"][0][\"name\"]\n",
    "\n",
    "def download(url, dest_folder):\n",
    "    try:\n",
    "        mid, override = parse_mid_and_override(url)\n",
    "        vid = override or get_vid(mid)\n",
    "        dl_url, fname = fetch_dl_info(vid)\n",
    "        print(f\"Processing: {url}\")\n",
    "        print(f\"Model ID: {mid}, Version ID: {vid}\")\n",
    "        print(f\"Filename: {fname}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        return\n",
    "\n",
    "    path = os.path.join(dest_folder, fname)\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        print(f\"File already exists: {path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Downloading to: {path}\")\n",
    "\n",
    "    try:\n",
    "        r = requests.get(\n",
    "            dl_url,\n",
    "            headers={\"Authorization\": f\"Bearer {API_KEY}\"},\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Download failed with status code {r.status_code}\")\n",
    "            return\n",
    "\n",
    "        total = int(r.headers.get(\"content-length\", 0))\n",
    "        bar = tqdm(total=total, unit=\"iB\", unit_scale=True, desc=fname)\n",
    "\n",
    "        with open(path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(8192):\n",
    "                f.write(chunk)\n",
    "                bar.update(len(chunk))\n",
    "\n",
    "        bar.close()\n",
    "        print(f\"Downloaded: {fname}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {fname}: {e}\")\n",
    "        if os.path.exists(path):\n",
    "            os.remove(path)  # Remove partially downloaded file\n",
    "\n",
    "# ─── Kick off downloads ───────────────────────────────────────────────────\n",
    "print(\"Starting downloads...\")\n",
    "\n",
    "print(\"\\nDownloading checkpoint models...\")\n",
    "for u in ckpt_links:\n",
    "    download(u, CKPT_PATH)\n",
    "\n",
    "print(\"\\n✨ All downloads completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdhXpG4p_gIz"
   },
   "source": [
    "CLONE KOHYA_SS REPO & INSTALL REQUIRNMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNsfUqg3Bo0B"
   },
   "source": [
    "NOTE: THIS SCRIPT EXICUTES IN CMD AT BACKGROUND THIS MIGHT TAKE A FEW MINS\n",
    "SINCE THIS RUN IN BACKGROUND CMD YOU CAN CHECK LIVE PROGRESS AT workspace/kohya_ss/logs/setup/kohya_ss_gui_.log\n",
    "TOOK ME ABOUT 10 MINS TO INSTALL BEFORE IT WAS READY TO USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6vQgvU2o_3gC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def run_command(command, cwd=None):\n",
    "    \"\"\"Run a shell command and return the result\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            command, \n",
    "            shell=True, \n",
    "            check=True, \n",
    "            capture_output=True, \n",
    "            text=True,\n",
    "            cwd=cwd\n",
    "        )\n",
    "        print(f\"✓ Command executed successfully: {command}\")\n",
    "        if result.stdout:\n",
    "            print(f\"Output: {result.stdout}\")\n",
    "        return result\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"✗ Error executing command: {command}\")\n",
    "        print(f\"Error: {e.stderr}\")\n",
    "        return None\n",
    "\n",
    "# Step 1: Change to workspace directory\n",
    "print(\"Step 1: Changing to /workspace directory...\")\n",
    "try:\n",
    "    os.chdir('/workspace')\n",
    "    print(f\"✓ Current directory: {os.getcwd()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"✗ /workspace directory not found. Using current directory instead.\")\n",
    "    print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Step 2: Clone the repository with recursive submodules\n",
    "print(\"\\nStep 2: Cloning kohya_ss repository...\")\n",
    "clone_command = \"git clone --recursive https://github.com/bmaltais/kohya_ss.git\"\n",
    "clone_result = run_command(clone_command)\n",
    "\n",
    "if clone_result:\n",
    "    # Step 3: Change to kohya_ss directory\n",
    "    print(\"\\nStep 3: Changing to kohya_ss directory...\")\n",
    "    try:\n",
    "        os.chdir('kohya_ss')\n",
    "        print(f\"✓ Current directory: {os.getcwd()}\")\n",
    "        \n",
    "        # Step 4: Run the setup script\n",
    "        print(\"\\nStep 4: Running setup-runpod.sh...\")\n",
    "        \n",
    "        # First, make sure the script is executable\n",
    "        run_command(\"chmod +x setup-runpod.sh\")\n",
    "        \n",
    "        # Run the setup script\n",
    "        setup_result = run_command(\"./setup-runpod.sh\")\n",
    "        \n",
    "        if setup_result:\n",
    "            print(\"\\n🎉 Setup completed successfully!\")\n",
    "        else:\n",
    "            print(\"\\n❌ Setup script failed. Check the error messages above.\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"✗ kohya_ss directory not found after cloning.\")\n",
    "else:\n",
    "    print(\"❌ Failed to clone repository. Please check your internet connection and try again.\")\n",
    "\n",
    "# Optional: List contents of current directory to verify\n",
    "print(f\"\\nContents of current directory ({os.getcwd()}):\")\n",
    "try:\n",
    "    contents = os.listdir('.')\n",
    "    for item in contents:\n",
    "        print(f\"  - {item}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error listing directory contents: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNsfUqg3Bo0B"
   },
   "source": [
    "START KOHYA_SS WEBUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nfHnzFvBogC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating venv...\n",
      "2025-06-18 19:13:46.676228: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-18 19:13:46.676321: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-18 19:13:46.676385: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-18 19:13:46.686632: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-18 19:13:51.622044: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2;36m19:14:19-822106\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kohya_ss GUI version: v25.\u001b[1;36m2.0\u001b[0m                          \n",
      "\u001b[2;36m                \u001b[0m                                                                \n",
      "\u001b[2;36m19:14:20-201915\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Submodule initialized and updated.                     \n",
      "\u001b[2;36m19:14:20-205221\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m nVidia toolkit detected                                \n",
      "\u001b[2;36m19:14:25-924419\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Torch \u001b[1;36m2.5\u001b[0m.\u001b[1;36m0\u001b[0m+cu124                                      \n",
      "\u001b[2;36m19:14:26-069209\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Torch backend: nVidia CUDA \u001b[1;36m12.4\u001b[0m cuDNN \u001b[1;36m90100\u001b[0m            \n",
      "\u001b[2;36m19:14:26-103760\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Torch detected GPU: NVIDIA GeForce RTX \u001b[1;36m3090\u001b[0m VRAM       \n",
      "\u001b[2;36m                \u001b[0m         24150MB Arch \u001b[1;36m8.6\u001b[0m Cores \u001b[1;36m82\u001b[0m                              \n",
      "\u001b[2;36m19:14:26-106722\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Python version is \u001b[1;36m3.10\u001b[0m.\u001b[1;36m12\u001b[0m \u001b[1m(\u001b[0mmain, May \u001b[1;36m27\u001b[0m \u001b[1;36m2025\u001b[0m, \u001b[1;92m17:12:29\u001b[0m\u001b[1m)\u001b[0m\n",
      "\u001b[2;36m                \u001b[0m         \u001b[1m[\u001b[0mGCC \u001b[1;36m11.4\u001b[0m.\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                                           \n",
      "\u001b[2;36m19:14:26-109378\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing/Validating requirements from                \n",
      "\u001b[2;36m                \u001b[0m         \u001b[35m/workspace/kohya_ss/\u001b[0m\u001b[95mrequirements_runpod.txt...\u001b[0m         \n",
      "\u001b[2;36m19:14:28-612334\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Looking in indexes: \u001b[4;94mhttps://pypi.org/simple,\u001b[0m           \n",
      "\u001b[2;36m                \u001b[0m         \u001b[4;94mhttps://download.pytorch.org/whl/cu124\u001b[0m                 \n",
      "\u001b[2;36m19:14:28-616918\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Obtaining \u001b[4;94mfile:///workspace/kohya_ss/sd-scripts\u001b[0m \u001b[1m(\u001b[0mfrom  \n",
      "\u001b[2;36m                \u001b[0m         -r \u001b[35m/workspace/kohya_ss/\u001b[0m\u001b[95mrequirements.txt\u001b[0m \u001b[1m(\u001b[0mline \u001b[1;36m38\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m     \n",
      "\u001b[2;36m19:14:28-626439\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing metadata \u001b[1m(\u001b[0msetup.py\u001b[1m)\u001b[0m: started                 \n",
      "\u001b[2;36m19:14:30-036951\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing metadata \u001b[1m(\u001b[0msetup.py\u001b[1m)\u001b[0m: finished with status    \n",
      "\u001b[2;36m                \u001b[0m         \u001b[32m'done'\u001b[0m                                                 \n",
      "\u001b[2;36m19:14:33-105155\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing collected packages: library                 \n",
      "\u001b[2;36m19:14:33-107224\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Attempting uninstall: library                          \n",
      "\u001b[2;36m19:14:33-108955\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Found existing installation: library \u001b[1;36m0.0\u001b[0m.\u001b[1;36m0\u001b[0m             \n",
      "\u001b[2;36m19:14:33-142026\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Uninstalling library-\u001b[1;36m0.0\u001b[0m.\u001b[1;36m0\u001b[0m:                            \n",
      "\u001b[2;36m19:14:46-388213\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Successfully uninstalled library-\u001b[1;36m0.0\u001b[0m.\u001b[1;36m0\u001b[0m                 \n",
      "\u001b[2;36m19:14:46-391804\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running setup.py develop for library                   \n",
      "\u001b[2;36m19:14:50-181222\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Successfully installed library-\u001b[1;36m0.0\u001b[0m.\u001b[1;36m0\u001b[0m                   \n",
      "\u001b[2;36m19:14:50-858302\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m headless: \u001b[3;91mFalse\u001b[0m                                        \n",
      "\u001b[2;36m19:14:50-874042\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using \u001b[33mshell\u001b[0m=\u001b[3;92mTrue\u001b[0m when running external commands\u001b[33m...\u001b[0m     \n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://167e5dded7daf7864f.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/workspace/kohya_ss')\n",
    "\n",
    "!./gui.sh --share"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
