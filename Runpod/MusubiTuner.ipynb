{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cb2751-7439-4737-a2f1-364cf0cb567b",
   "metadata": {},
   "source": [
    "# Run RVC in Runpod\n",
    "# NoteBook Created by Voiid (https://github.com/official-imvoiid)\n",
    "\n",
    "üìå Recommended Setup:\n",
    "- GPU: A6000 Ada  \n",
    "- Storage: 70GB total  \n",
    "  - 50GB on persistent  \n",
    "  - 20GB on temporary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ddc81f-9fac-443e-995d-c718a0200c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: Initial Setup\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def run_command(cmd, check=True):\n",
    "    \"\"\"Run shell command and print output\"\"\"\n",
    "    print(f\"Running: {cmd}\")\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    if result.stdout:\n",
    "        print(result.stdout)\n",
    "    if result.stderr and result.returncode != 0:\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "    if check and result.returncode != 0:\n",
    "        raise Exception(f\"Command failed: {cmd}\")\n",
    "    return result\n",
    "\n",
    "# Create workspace with desired structure\n",
    "workspace = Path(\"/workspace\")\n",
    "workspace.mkdir(exist_ok=True)\n",
    "os.chdir(workspace)\n",
    "\n",
    "!git clone https://github.com/kohya-ss/musubi-tuner.git\n",
    "run_command(\"mkdir -p musubi-tuner/inputfolder\")\n",
    "run_command(\"mkdir -p musubi-tuner/outputfolder\")\n",
    "\n",
    "print(\"‚úÖ Initial Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea071f-49ca-439d-80ca-d359a824e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: Install Dependencies\n",
    "\n",
    "!python -m pip install --upgrade pip\n",
    "\n",
    "# Install PyTorch with CUDA support\n",
    "print(\"üì¶ Installing PyTorch with CUDA support...\")\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "# Install optional dependencies\n",
    "print(\"üì¶ Installing optional dependencies...\")\n",
    "!pip install accelerate==1.6.0 av==14.0.1 bitsandbytes==0.45.4 diffusers==0.32.1 einops==0.7.0 huggingface-hub==0.30.0 opencv-python==4.10.0.84 \"pillow>=10.2.0\" safetensors==0.4.5 \"sageattention>=1.0.6\" toml==0.10.2 tqdm==4.67.1 transformers==4.46.3 voluptuous==0.15.2 ftfy==6.3.1 easydict==1.13 ascii-magic matplotlib tensorboard\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8d5da-858f-49d2-8a12-c827c4b58579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/workspace/musubi-tuner')\n",
    "print(\"üì¶ Installing requirements...\")\n",
    "!pip install -e .\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265cf29-3a1d-4894-bfcf-ca1925785630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: Configure Accelerate for 48GB VRAM\n",
    "from pathlib import Path\n",
    "\n",
    "# Create accelerate config optimized for 48GB VRAM\n",
    "config_dir = Path.home() / \".cache/huggingface/accelerate\"\n",
    "config_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Optimized config for 48GB VRAM\n",
    "accelerate_config = \"\"\"compute_environment: LOCAL_MACHINE\n",
    "distributed_type: 'NO'\n",
    "downcast_bf16: 'no'\n",
    "gpu_ids: all\n",
    "machine_rank: 0\n",
    "main_training_function: main\n",
    "mixed_precision: bf16\n",
    "num_machines: 1\n",
    "num_processes: 1\n",
    "rdzv_backend: static\n",
    "same_network: true\n",
    "tpu_env: []\n",
    "tpu_use_cluster: false\n",
    "tpu_use_sudo: false\n",
    "use_cpu: false\n",
    "\"\"\"\n",
    "\n",
    "with open(config_dir / \"default_config.yaml\", \"w\") as f:\n",
    "    f.write(accelerate_config)\n",
    "    \n",
    "print(\"‚öôÔ∏è Accelerate configured for 48GB VRAM single GPU training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42f9400-fe34-4b66-b5bf-89855eb4152e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CELL 4: Download Models to ckpt folder for 48GB VRAM\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# Define workspace path (adjust this to your actual workspace location)\n",
    "workspace = Path(\"/workspace\")  # or Path.cwd() if you want current directory\n",
    "\n",
    "# Define run_command function\n",
    "def run_command(cmd):\n",
    "    \"\"\"Execute shell command\"\"\"\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Command failed: {cmd}\")\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "    return result\n",
    "\n",
    "# Model paths matching HunyuanVideo directory structure\n",
    "ckpt_dir = workspace / \"musubi-tuner/ckpt\"\n",
    "hunyuan_dir = ckpt_dir / \"hunyuan-video-t2v-720p\"\n",
    "\n",
    "# Create directory structure\n",
    "transformers_dir = hunyuan_dir / \"transformers\"\n",
    "vae_dir = hunyuan_dir / \"vae\"\n",
    "text_encoder_dir = ckpt_dir / \"text_encoder\"\n",
    "text_encoder_2_dir = ckpt_dir / \"text_encoder_2\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "transformers_dir.mkdir(parents=True, exist_ok=True)\n",
    "vae_dir.mkdir(parents=True, exist_ok=True)\n",
    "text_encoder_dir.mkdir(parents=True, exist_ok=True)\n",
    "text_encoder_2_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model file paths\n",
    "dit_path = transformers_dir / \"mp_rank_00_model_states.pt\"\n",
    "vae_path = vae_dir / \"pytorch_model.pt\"\n",
    "llm_path = text_encoder_dir / \"model.safetensors\"  # LLaMA text encoder\n",
    "clip_path = text_encoder_2_dir / \"model.safetensors\"  # CLIP text encoder\n",
    "\n",
    "print(\"üì• Downloading HunyuanVideo models for 48GB VRAM setup...\")\n",
    "\n",
    "# Download DiT model (main transformer)\n",
    "if not dit_path.exists():\n",
    "    print(\"Downloading DiT transformer model (this may take a while)...\")\n",
    "    try:\n",
    "        hf_hub_download(\n",
    "            repo_id=\"tencent/HunyuanVideo\",\n",
    "            filename=\"hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt\",\n",
    "            local_dir=str(ckpt_dir),\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "        print(\"‚úÖ DiT model downloaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"HF download failed, trying wget: {e}\")\n",
    "        run_command(f\"wget -O {dit_path} https://huggingface.co/tencent/HunyuanVideo/resolve/main/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt\")\n",
    "\n",
    "# Download VAE model\n",
    "if not vae_path.exists():\n",
    "    print(\"Downloading VAE model...\")\n",
    "    try:\n",
    "        hf_hub_download(\n",
    "            repo_id=\"tencent/HunyuanVideo\",\n",
    "            filename=\"hunyuan-video-t2v-720p/vae/pytorch_model.pt\",\n",
    "            local_dir=str(ckpt_dir),\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "        print(\"‚úÖ VAE model downloaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"HF download failed, trying wget: {e}\")\n",
    "        run_command(f\"wget -O {vae_path} https://huggingface.co/tencent/HunyuanVideo/resolve/main/hunyuan-video-t2v-720p/vae/pytorch_model.pt\")\n",
    "\n",
    "# Download LLaMA Text Encoder (text_encoder) \n",
    "    print(\"Downloading LLaMA text encoder...\")\n",
    "    try:\n",
    "        # Try the Comfy-Org repackaged version first as it's more reliable\n",
    "        print(\"Trying Comfy-Org repackaged version...\")\n",
    "        downloaded_file = hf_hub_download(\n",
    "            repo_id=\"Comfy-Org/HunyuanVideo_repackaged\",\n",
    "            filename=\"split_files/text_encoders/llava_llama3_fp16.safetensors\",\n",
    "            local_dir=None,  # Don't preserve directory structure\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "        # Use shutil.copy2 instead of os.rename to handle cross-device links\n",
    "        shutil.copy2(downloaded_file, llm_path)\n",
    "        print(\"‚úÖ LLaMA text encoder downloaded from Comfy-Org repo\")\n",
    "    except Exception as e:\n",
    "        print(f\"Comfy-Org download failed: {e}\")\n",
    "        # Try alternative LLaMA model\n",
    "        try:\n",
    "            print(\"Trying alternative LLaMA model...\")\n",
    "            downloaded_file = hf_hub_download(\n",
    "                repo_id=\"Comfy-Org/HunyuanVideo_repackaged\",\n",
    "                filename=\"split_files/text_encoders/llama3_8b_instruct_fp16.safetensors\",\n",
    "                local_dir=None,\n",
    "                local_dir_use_symlinks=False\n",
    "            )\n",
    "            shutil.copy2(downloaded_file, llm_path)\n",
    "            print(\"‚úÖ Alternative LLaMA text encoder downloaded\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Alternative LLaMA download also failed: {e2}\")\n",
    "            # Try direct wget as last resort\n",
    "            try:\n",
    "                print(\"Trying direct wget download...\")\n",
    "                result = run_command(f\"wget -O {llm_path} https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/text_encoders/llava_llama3_fp16.safetensors\")\n",
    "                if result.returncode == 0:\n",
    "                    print(\"‚úÖ LLaMA text encoder downloaded via wget\")\n",
    "                else:\n",
    "                    print(\"‚ùå All LLaMA download methods failed\")\n",
    "            except Exception as e3:\n",
    "                print(f\"Wget download failed: {e3}\")\n",
    "\n",
    "# Download CLIP Text Encoder (text_encoder_2) \n",
    "if not clip_path.exists():\n",
    "    print(\"Downloading CLIP text encoder...\")\n",
    "    try:\n",
    "        # Try the Comfy-Org repackaged version first\n",
    "        print(\"Trying Comfy-Org repackaged version...\")\n",
    "        downloaded_file = hf_hub_download(\n",
    "            repo_id=\"Comfy-Org/HunyuanVideo_repackaged\",\n",
    "            filename=\"split_files/text_encoders/clip_l.safetensors\",\n",
    "            local_dir=None,  # Don't preserve directory structure\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "        # Use shutil.copy2 instead of os.rename to handle cross-device links\n",
    "        shutil.copy2(downloaded_file, clip_path)\n",
    "        print(\"‚úÖ CLIP text encoder downloaded from Comfy-Org repo\")\n",
    "    except Exception as e:\n",
    "        print(f\"Comfy-Org CLIP download failed: {e}\")\n",
    "        # Try direct wget as fallback\n",
    "        try:\n",
    "            print(\"Trying direct wget download...\")\n",
    "            result = run_command(f\"wget -O {clip_path} https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/text_encoders/clip_l.safetensors\")\n",
    "            if result.returncode == 0:\n",
    "                print(\"‚úÖ CLIP text encoder downloaded via wget\")\n",
    "            else:\n",
    "                print(\"‚ùå All CLIP download methods failed\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Wget download failed: {e2}\")\n",
    "\n",
    "# Verify downloads\n",
    "print(\"\\nüîç Verifying downloads...\")\n",
    "models_status = {\n",
    "    \"DiT Transformer\": dit_path.exists(),\n",
    "    \"VAE\": vae_path.exists(), \n",
    "    \"LLaMA Text Encoder\": llm_path.exists(),\n",
    "    \"CLIP Text Encoder\": clip_path.exists()\n",
    "}\n",
    "\n",
    "for model_name, exists in models_status.items():\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {model_name}\")\n",
    "\n",
    "if all(models_status.values()):\n",
    "    print(\"\\nüéâ All models downloaded successfully!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Some models failed to download. Check the errors above.\")\n",
    "    print(\"\\nAlternative options:\")\n",
    "    print(\"1. Try running the script again (some downloads may be temporary failures)\")\n",
    "    print(\"2. Manually download missing files from:\")\n",
    "    print(\"   - https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged\")\n",
    "    print(\"   - https://huggingface.co/tencent/HunyuanVideo\")\n",
    "\n",
    "print(\"\\nüìÅ Final directory structure:\")\n",
    "print(f\"   {ckpt_dir}/\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ hunyuan-video-t2v-720p/\")\n",
    "print(f\"   ‚îÇ   ‚îú‚îÄ‚îÄ transformers/\")\n",
    "print(f\"   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mp_rank_00_model_states.pt\")\n",
    "print(f\"   ‚îÇ   ‚îî‚îÄ‚îÄ vae/\")\n",
    "print(f\"   ‚îÇ       ‚îî‚îÄ‚îÄ pytorch_model.pt\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ text_encoder/\")\n",
    "print(f\"   ‚îÇ   ‚îî‚îÄ‚îÄ model.safetensors\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ text_encoder_2/\")\n",
    "print(f\"       ‚îî‚îÄ‚îÄ model.safetensors\")\n",
    "\n",
    "# Additional helpful information\n",
    "print(f\"\\nüìä Estimated total download size: ~26GB\")\n",
    "print(f\"üíæ Make sure you have sufficient disk space available\")\n",
    "if any(models_status.values()):\n",
    "    print(f\"üöÄ You can now proceed with HunyuanVideo training/inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27879baf-580b-40f0-9160-dc6c62225155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: Create Dataset Configuration Template\n",
    "\n",
    "dataset_config = \"\"\"# Dataset configuration for HunyuanVideo training\n",
    "# Place your videos and captions in /workspace/musubi-tuner/inputfolder/\n",
    "\n",
    "[general]\n",
    "resolution = [768, 768]\n",
    "caption_extension = \".txt\"\n",
    "batch_size = 1\n",
    "enable_bucket = true\n",
    "bucket_no_upscale = false\n",
    "\n",
    "[[datasets]]\n",
    "video_directory = \"/workspace/musubi-tuner/inputfolder\"\n",
    "caption_extension = \".txt\"\n",
    "num_repeats = 1\n",
    "frame_extraction = \"head\"\n",
    "cache_directory = \"/workspace/musubi-tuner/outputfolder\"\n",
    "\"\"\"\n",
    "\n",
    "# Write dataset config\n",
    "dataset_config_path = workspace / \"musubi-tuner/dataset.toml\"\n",
    "with open(dataset_config_path, \"w\") as f:\n",
    "    f.write(dataset_config)\n",
    "\n",
    "print(f\"‚úÖ Dataset configuration created at: {dataset_config_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea84a3b-a67b-4361-8373-6ef51e0c5751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: Create Training Scripts with Direct Correct Paths \n",
    "\n",
    "# Cache latents script \n",
    "cache_latents_script = f\"\"\"#!/bin/bash\n",
    "cd /workspace/musubi-tuner\n",
    "python src/musubi_tuner/cache_latents.py \\\\\n",
    "    --dataset_config dataset.toml \\\\\n",
    "    --vae ckpt/hunyuan-video-t2v-720p/vae/pytorch_model.pt \\\\\n",
    "    --vae_chunk_size 64 \\\\\n",
    "    --vae_tiling\n",
    "\"\"\"\n",
    "\n",
    "# Cache text encoder outputs script\n",
    "cache_text_script = f\"\"\"#!/bin/bash\n",
    "cd /workspace/musubi-tuner\n",
    "python src/musubi_tuner/cache_text_encoder_outputs.py \\\\\n",
    "    --dataset_config dataset.toml \\\\\n",
    "    --text_encoder1 ckpt/text_encoder/model.safetensors \\\\\n",
    "    --text_encoder2 ckpt/text_encoder_2/model.safetensors \\\\\n",
    "    --batch_size 32\n",
    "\"\"\"\n",
    "\n",
    "# Training script optimized for 42GB VRAM \n",
    "train_script = f\"\"\"#!/bin/bash\n",
    "cd /workspace/musubi-tuner\n",
    "accelerate launch --num_cpu_threads_per_process 1 --mixed_precision bf16 src/musubi_tuner/hv_train_network.py \\\\\n",
    "    --dit ckpt/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt \\\\\n",
    "    --dataset_config dataset.toml \\\\\n",
    "    --sdpa \\\\\n",
    "    --mixed_precision bf16 \\\\\n",
    "    --fp8_base \\\\\n",
    "    --optimizer_type adamw8bit \\\\\n",
    "    --learning_rate 1e-4 \\\\\n",
    "    --lr_scheduler cosine_with_restarts \\\\\n",
    "    --lr_warmup_steps 100 \\\\\n",
    "    --gradient_checkpointing \\\\\n",
    "    --max_data_loader_n_workers 4 \\\\\n",
    "    --persistent_data_loader_workers \\\\\n",
    "    --network_module networks.lora \\\\\n",
    "    --network_dim 64 \\\\\n",
    "    --network_alpha 32 \\\\\n",
    "    --timestep_sampling shift \\\\\n",
    "    --discrete_flow_shift 7.0 \\\\\n",
    "    --max_train_epochs 500 \\\\\n",
    "    --save_every_n_epochs 50 \\\\\n",
    "    --gradient_accumulation_steps 2 \\\\\n",
    "    --max_grad_norm 1.0 \\\\\n",
    "    --seed 42 \\\\\n",
    "    --output_dir outputfolder \\\\\n",
    "    --output_name Hunyuan-lora \\\\\n",
    "    --logging_dir logs\n",
    "\"\"\"\n",
    "\n",
    "# Write scripts\n",
    "scripts = [\n",
    "    (\"cache_latents.sh\", cache_latents_script),\n",
    "    (\"cache_text_encoders.sh\", cache_text_script), \n",
    "    (\"train.sh\", train_script)\n",
    "]\n",
    "\n",
    "for script_name, script_content in scripts:\n",
    "    script_path = workspace / \"musubi-tuner\" / script_name\n",
    "    with open(script_path, \"w\") as f:\n",
    "        f.write(script_content)\n",
    "    run_command(f\"chmod +x {script_path}\")\n",
    "    print(f\"‚úÖ Created executable script: {script_name}\")\n",
    "\n",
    "print(\"\\nüìÅ Using direct paths based on your actual directory structure:\")\n",
    "print(\"‚îú‚îÄ‚îÄ VAE: ckpt/hunyuan-video-t2v-720p/vae/pytorch_model.pt\")\n",
    "print(\"‚îú‚îÄ‚îÄ DIT: ckpt/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt\") \n",
    "print(\"‚îú‚îÄ‚îÄ Text Encoder 1: ckpt/text_encoder/model.safetensors\")\n",
    "print(\"‚îî‚îÄ‚îÄ Text Encoder 2: ckpt/text_encoder_2/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25f79c0-561a-42e0-800b-076e19e4fec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start cache latents\n",
    "import os\n",
    "os.chdir('/workspace/musubi-tuner')\n",
    "print(\"üì¶ Installing requirements...\")\n",
    "!./cache_latents.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300e7863-8797-4026-b3b8-7a9326d63f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start cache textencoder\n",
    "import os\n",
    "os.chdir('/workspace/musubi-tuner')\n",
    "print(\"üì¶ Installing requirements...\")\n",
    "!./cache_text_encoders.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39c470-dd8f-4484-81ce-8250a537e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "import os\n",
    "os.chdir('/workspace/musubi-tuner')\n",
    "print(\"üì¶ Installing requirements...\")\n",
    "!./train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c55610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Lora To Generate Videos\n",
    "\n",
    "# for 5 second video (--video_length 121)\n",
    "\n",
    "  # --video_length Frames (length of your video) \n",
    "  # formula 4 x n + 1\n",
    "  # ig for 30 sec video 30 x 24 FPS +1 = 721 Frames\n",
    "  # ig for 5 sec ideo 5 x 24 FPS +1 = 121 Frames\n",
    "\n",
    "  # Please upload All your lora models at /workspace/musubi-tuner/ckpt/text_encoder_2/\n",
    "\n",
    "!python hv_generate_video.py \\\n",
    "  --fp8 \\\n",
    "  --video_size 544 960 \\\n",
    "  --video_length 121 \\\n",
    "  --infer_steps 30 \\\n",
    "  --prompt \"Your Prompt here\" \\\n",
    "  --save_path /workspace/musubi-tuner/output \\\n",
    "  --output_type both \\\n",
    "  --dit /workspace/musubi-tuner/ckpt/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt \\\n",
    "  --vae /workspace/musubi-tuner/ckpt/hunyuan-video-t2v-720p/vae/pytorch_model.pt \\\n",
    "  --text_encoder1 /workspace/musubi-tuner/ckpt/text_encoder/model.safetensors \\\n",
    "  --text_encoder2 /workspace/musubi-tuner/ckpt/text_encoder_2/model.safetensors \\\n",
    "  --lora_weight /workspace/musubi-tuner/outputfolder/Name_of_your_Lora_here.safetensors \\\n",
    "  --lora_multiplier 1.0 \\\n",
    "  --attn_mode sdpa \\\n",
    "  --split_attn \\\n",
    "  --vae_chunk_size 32 \\\n",
    "  --vae_spatial_tile_sample_min_size 128 \\\n",
    "  --seed 1234"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
